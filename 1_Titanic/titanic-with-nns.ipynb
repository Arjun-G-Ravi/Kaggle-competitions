{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-01-06T11:29:55.352119Z","iopub.status.busy":"2024-01-06T11:29:55.351831Z","iopub.status.idle":"2024-01-06T11:30:00.167579Z","shell.execute_reply":"2024-01-06T11:30:00.166826Z","shell.execute_reply.started":"2024-01-06T11:29:55.352092Z"},"trusted":true},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","import matplotlib.pyplot as plt\n","import torch\n","import seaborn as sns\n","import os\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn.functional as F\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"markdown","metadata":{},"source":["# TODO\n","- See if ticket and cabin have any importance\n","- Try data imputation instead of fillna"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-01-06T11:30:00.175161Z","iopub.status.busy":"2024-01-06T11:30:00.174898Z","iopub.status.idle":"2024-01-06T11:30:00.203782Z","shell.execute_reply":"2024-01-06T11:30:00.202893Z","shell.execute_reply.started":"2024-01-06T11:30:00.175129Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv('/home/arjun/Desktop/GitHub/Kaggle-competitions/_Datasets/Titanic/train.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Survived  Pclass  \\\n","0            1         0       3   \n","1            2         1       1   \n","2            3         1       3   \n","3            4         1       1   \n","4            5         0       3   \n","\n","                                                Name     Sex   Age  SibSp  \\\n","0                            Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                             Heikkinen, Miss. Laina  female  26.0      0   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                           Allen, Mr. William Henry    male  35.0      0   \n","\n","   Parch            Ticket     Fare Cabin Embarked  \n","0      0         A/5 21171   7.2500   NaN        S  \n","1      0          PC 17599  71.2833   C85        C  \n","2      0  STON/O2. 3101282   7.9250   NaN        S  \n","3      0            113803  53.1000  C123        S  \n","4      0            373450   8.0500   NaN        S  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["y = df['Survived']"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-01-06T11:30:00.206566Z","iopub.status.busy":"2024-01-06T11:30:00.206322Z","iopub.status.idle":"2024-01-06T11:30:00.220938Z","shell.execute_reply":"2024-01-06T11:30:00.220092Z","shell.execute_reply.started":"2024-01-06T11:30:00.206543Z"},"trusted":true},"outputs":[],"source":["df = df.drop(['Name', 'Ticket', 'Cabin'], axis=1)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-01-06T11:30:00.222512Z","iopub.status.busy":"2024-01-06T11:30:00.222193Z","iopub.status.idle":"2024-01-06T11:30:00.343789Z","shell.execute_reply":"2024-01-06T11:30:00.342830Z","shell.execute_reply.started":"2024-01-06T11:30:00.222482Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>7.2500</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>71.2833</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7.9250</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>53.1000</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8.0500</td>\n","      <td>S</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n","0            1         0       3    male  22.0      1      0   7.2500        S\n","1            2         1       1  female  38.0      1      0  71.2833        C\n","2            3         1       3  female  26.0      0      0   7.9250        S\n","3            4         1       1  female  35.0      1      0  53.1000        S\n","4            5         0       3    male  35.0      0      0   8.0500        S"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-01-06T11:30:00.345227Z","iopub.status.busy":"2024-01-06T11:30:00.344960Z","iopub.status.idle":"2024-01-06T11:30:00.353449Z","shell.execute_reply":"2024-01-06T11:30:00.352480Z","shell.execute_reply.started":"2024-01-06T11:30:00.345203Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_425805/909058363.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  df['Sex'] = df['Sex'].replace({'male': 0, 'female': 1})\n","/tmp/ipykernel_425805/909058363.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  df['Embarked'] = df['Embarked'].replace({'S':1, 'C':2, 'Q':3})\n"]}],"source":["df['Sex'] = df['Sex'].replace({'male': 0, 'female': 1})\n","df['Embarked'] = df['Embarked'].replace({'S':1, 'C':2, 'Q':3})"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-01-06T11:30:00.355104Z","iopub.status.busy":"2024-01-06T11:30:00.354871Z","iopub.status.idle":"2024-01-06T11:30:00.376211Z","shell.execute_reply":"2024-01-06T11:30:00.375457Z","shell.execute_reply.started":"2024-01-06T11:30:00.355081Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>7.2500</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>71.2833</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7.9250</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>53.1000</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8.0500</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n","0            1         0       3    0  22.0      1      0   7.2500       1.0\n","1            2         1       1    1  38.0      1      0  71.2833       2.0\n","2            3         1       3    1  26.0      0      0   7.9250       1.0\n","3            4         1       1    1  35.0      1      0  53.1000       1.0\n","4            5         0       3    0  35.0      0      0   8.0500       1.0"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df.fillna(df.mean(), inplace=True)\n","df.head()"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["df_randomized = df.sample(frac=1).reset_index(drop=True)\n","train_df = df_randomized[:800]\n","test_df = df_randomized[800:]"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>800</th>\n","      <td>632</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>51.000000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7.0542</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>801</th>\n","      <td>355</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>29.699118</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7.2250</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>802</th>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>54.000000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>51.8625</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>803</th>\n","      <td>71</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>32.000000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.5000</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>804</th>\n","      <td>487</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>35.000000</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>90.0000</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>886</th>\n","      <td>316</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>26.000000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7.8542</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>887</th>\n","      <td>227</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>19.000000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10.5000</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>888</th>\n","      <td>755</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>48.000000</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>65.0000</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>806</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>31.000000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7.7750</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>890</th>\n","      <td>75</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>32.000000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>56.4958</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>91 rows × 9 columns</p>\n","</div>"],"text/plain":["     PassengerId  Survived  Pclass  Sex        Age  SibSp  Parch     Fare  \\\n","800          632         0       3    0  51.000000      0      0   7.0542   \n","801          355         0       3    0  29.699118      0      0   7.2250   \n","802            7         0       1    0  54.000000      0      0  51.8625   \n","803           71         0       2    0  32.000000      0      0  10.5000   \n","804          487         1       1    1  35.000000      1      0  90.0000   \n","..           ...       ...     ...  ...        ...    ...    ...      ...   \n","886          316         1       3    1  26.000000      0      0   7.8542   \n","887          227         1       2    0  19.000000      0      0  10.5000   \n","888          755         1       2    1  48.000000      1      2  65.0000   \n","889          806         0       3    0  31.000000      0      0   7.7750   \n","890           75         1       3    0  32.000000      0      0  56.4958   \n","\n","     Embarked  \n","800       1.0  \n","801       2.0  \n","802       1.0  \n","803       1.0  \n","804       1.0  \n","..        ...  \n","886       1.0  \n","887       1.0  \n","888       1.0  \n","889       1.0  \n","890       1.0  \n","\n","[91 rows x 9 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["test_df"]},{"cell_type":"markdown","metadata":{},"source":["# Model Creation"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-01-06T11:30:00.410359Z","iopub.status.busy":"2024-01-06T11:30:00.410106Z","iopub.status.idle":"2024-01-06T11:30:00.438739Z","shell.execute_reply":"2024-01-06T11:30:00.437939Z","shell.execute_reply.started":"2024-01-06T11:30:00.410336Z"},"trusted":true},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["num_epochs = 1000\n","lr =.001\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-01-06T11:30:00.443127Z","iopub.status.busy":"2024-01-06T11:30:00.442389Z","iopub.status.idle":"2024-01-06T11:30:00.606235Z","shell.execute_reply":"2024-01-06T11:30:00.605476Z","shell.execute_reply.started":"2024-01-06T11:30:00.443092Z"},"trusted":true},"outputs":[],"source":["class NeuralNet(nn.Module):\n","    def __init__(self, inp_size, h1, h2, h3, h4, h5, out_size):\n","        super(NeuralNet, self).__init__()\n","        self.inp_size = inp_size\n","        self.lay1 = nn.Linear(inp_size, h1)\n","        self.lay2 = nn.ReLU()\n","        self.lay3 = nn.Linear(h1, h2)\n","        self.lay4 = nn.ReLU()\n","        self.lay5 = nn.Linear(h2, h3)\n","        self.lay6 = nn.ReLU()\n","        self.lay7 = nn.Linear(h3, h4)\n","        self.lay8 = nn.ReLU()\n","        self.lay9 = nn.Linear(h4, h5)\n","        self.lay10 = nn.ReLU()\n","        self.lay11 = nn.Linear(h5, out_size)\n","        \n","    def forward(self,x):\n","        out = self.lay1(x)\n","        out = self.lay2(out)\n","        out = self.lay3(out)\n","        out = self.lay4(out)\n","        out = self.lay5(out)\n","        out = self.lay6(out)\n","        out = self.lay7(out)\n","        out = self.lay8(out)\n","        out = self.lay9(out)\n","        out = self.lay10(out)\n","        out = self.lay11(out)  # We don't apply sotmax the cross entropy loss will do that for us\n","        return out\n","    \n","model = NeuralNet(8,30,60,120,60,30,2).to(device)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["class NeuralNet(nn.Module):\n","    def __init__(self, inp_size, h1, h2, out_size):\n","        super(NeuralNet, self).__init__()\n","        self.fc1 = nn.Linear(inp_size, h1)\n","        self.bn1 = nn.BatchNorm1d(h1)\n","        self.drop1 = nn.Dropout(0.5)\n","        self.fc2 = nn.Linear(h1, h2)\n","        self.bn2 = nn.BatchNorm1d(h2)\n","        self.drop2 = nn.Dropout(0.5)\n","        self.fc3 = nn.Linear(h2, out_size)\n","        \n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.bn1(x)\n","        x = nn.ReLU()(x)\n","        x = self.drop1(x)\n","        x = self.fc2(x)\n","        x = self.bn2(x)\n","        x = nn.ReLU()(x)\n","        x = self.drop2(x)\n","        x = self.fc3(x)\n","        return x\n","\n","model = NeuralNet(8, 30, 15, 2).to(device)\n","    "]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-01-06T11:30:00.607610Z","iopub.status.busy":"2024-01-06T11:30:00.607327Z","iopub.status.idle":"2024-01-06T11:30:00.612091Z","shell.execute_reply":"2024-01-06T11:30:00.611228Z","shell.execute_reply.started":"2024-01-06T11:30:00.607584Z"},"trusted":true},"outputs":[],"source":["lossCategory = nn.CrossEntropyLoss()\n","optimiser = torch.optim.Adam(model.parameters(), lr = lr)"]},{"cell_type":"markdown","metadata":{},"source":["# Training Model"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-01-06T11:30:00.613569Z","iopub.status.busy":"2024-01-06T11:30:00.613260Z","iopub.status.idle":"2024-01-06T11:30:00.622669Z","shell.execute_reply":"2024-01-06T11:30:00.621949Z","shell.execute_reply.started":"2024-01-06T11:30:00.613536Z"},"trusted":true},"outputs":[],"source":["train_loader = DataLoader(dataset=torch.tensor(np.array(train_df)), shuffle=True, batch_size=1000)\n","test_loader = DataLoader(dataset=torch.tensor(np.array(test_df)), shuffle=True, batch_size=1000)"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-01-06T11:30:00.624057Z","iopub.status.busy":"2024-01-06T11:30:00.623747Z","iopub.status.idle":"2024-01-06T11:32:44.093167Z","shell.execute_reply":"2024-01-06T11:32:44.092168Z","shell.execute_reply.started":"2024-01-06T11:30:00.624034Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch:100/1000 Loss:0.5569859743118286\n","Epoch:200/1000 Loss:0.48526638746261597\n","Epoch:300/1000 Loss:0.4338216781616211\n","Epoch:400/1000 Loss:0.39321479201316833\n","Epoch:500/1000 Loss:0.33523741364479065\n","Epoch:600/1000 Loss:0.30628880858421326\n","Epoch:700/1000 Loss:0.3082524836063385\n","Epoch:800/1000 Loss:0.28224635124206543\n","Epoch:900/1000 Loss:0.2775838375091553\n","Epoch:1000/1000 Loss:0.26987019181251526\n"]}],"source":["for epoch in range(num_epochs):\n","    avg_loss = 0\n","    for i,batch in enumerate(train_loader):\n","\n","        y = batch[:,1].to(device).long()\n","        X =torch.cat((batch[:, :1], batch[:, 2:]), dim=1).to(device).to(torch.float32)\n","\n","        # Forward pass\n","        output = model(X)\n","        \n","        # Backward pass\n","        loss = lossCategory(output, y)\n","        loss.backward()\n","        optimiser.step()\n","        optimiser.zero_grad()\n","        avg_loss += loss\n","\n","    if not ((epoch+1)%100): print(f\"Epoch:{epoch+1}/{num_epochs} Loss:{avg_loss/len(train_loader)}\")"]},{"cell_type":"markdown","metadata":{},"source":["# Checking Accuracy"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 89.0\n"]},{"data":{"text/plain":["(torch.Size([800, 8]), torch.Size([800]))"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["correct = 0\n","total = 0\n","for i, batch in enumerate(train_loader):\n","    X = torch.cat((batch[:, :1], batch[:, 2:]), dim=1).to(device).to(torch.float32)\n","    y = batch[:, 1].to(device).long()\n","    output = model(X)\n","    softmax_output = F.softmax(output, dim=-1)\n","    _, y_pred = torch.max(softmax_output, dim=-1)\n","    correct += (y_pred == y).sum().item()\n","    total += y.size(0)\n","print('Accuracy:', correct / total * 100)\n","X.shape, y.shape, "]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 68.13186813186813\n"]}],"source":["correct = 0\n","total = 0\n","for i, batch in enumerate(test_loader):\n","    X = torch.cat((batch[:, :1], batch[:, 2:]), dim=1).to(device).to(torch.float32)\n","    y = batch[:, 1].to(device).long()\n","    output = model(X)\n","    softmax_output = F.softmax(output, dim=-1)\n","    _, y_pred = torch.max(softmax_output, dim=-1)\n","    correct += (y_pred == y).sum().item()\n","    total += y.size(0)\n","print('Accuracy:', correct / total * 100)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Inference on Test Dataset"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-01-06T11:32:44.675693Z","iopub.status.busy":"2024-01-06T11:32:44.675413Z","iopub.status.idle":"2024-01-06T11:32:44.695983Z","shell.execute_reply":"2024-01-06T11:32:44.695122Z","shell.execute_reply.started":"2024-01-06T11:32:44.675663Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_425805/2239982465.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  df['Sex'] = df['Sex'].replace({'male': 0, 'female': 1})\n","/tmp/ipykernel_425805/2239982465.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  df['Embarked'] = df['Embarked'].replace({'S':1, 'C':2, 'Q':3})\n"]},{"data":{"text/plain":["(torch.Size([418, 8]), (418, 8))"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('/home/arjun/Desktop/GitHub/Kaggle-competitions/_Datasets/Titanic/test.csv')\n","df = df.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n","df['Sex'] = df['Sex'].replace({'male': 0, 'female': 1})\n","df['Embarked'] = df['Embarked'].replace({'S':1, 'C':2, 'Q':3})\n","df.fillna(df.mean(), inplace=True)\n","ds = torch.tensor(np.array(df))\n","test_loader = torch.utils.data.DataLoader(dataset=ds, shuffle=False, batch_size=1)\n","ds.shape,df.shape"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-01-06T11:32:44.704585Z","iopub.status.busy":"2024-01-06T11:32:44.704309Z","iopub.status.idle":"2024-01-06T11:32:44.957845Z","shell.execute_reply":"2024-01-06T11:32:44.956958Z","shell.execute_reply.started":"2024-01-06T11:32:44.704562Z"},"trusted":true},"outputs":[{"ename":"ValueError","evalue":"Expected more than 1 value per channel when training, got input size torch.Size([1, 30])","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_loader):\n\u001b[1;32m      4\u001b[0m         X \u001b[38;5;241m=\u001b[39mbatch\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m----> 5\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m         softmax_output \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m         l\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39margmax(softmax_output)\u001b[38;5;241m.\u001b[39mitem())\n","File \u001b[0;32m~/Desktop/AI_ENV/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Desktop/AI_ENV/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[13], line 14\u001b[0m, in \u001b[0;36mNeuralNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x)\n\u001b[0;32m---> 14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mReLU()(x)\n\u001b[1;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop1(x)\n","File \u001b[0;32m~/Desktop/AI_ENV/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Desktop/AI_ENV/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/Desktop/AI_ENV/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:175\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Desktop/AI_ENV/lib/python3.10/site-packages/torch/nn/functional.py:2507\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2494\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2495\u001b[0m         batch_norm,\n\u001b[1;32m   2496\u001b[0m         (\u001b[38;5;28minput\u001b[39m, running_mean, running_var, weight, bias),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2504\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m   2505\u001b[0m     )\n\u001b[1;32m   2506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m-> 2507\u001b[0m     \u001b[43m_verify_batch_size\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[1;32m   2510\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled\n\u001b[1;32m   2511\u001b[0m )\n","File \u001b[0;32m~/Desktop/AI_ENV/lib/python3.10/site-packages/torch/nn/functional.py:2475\u001b[0m, in \u001b[0;36m_verify_batch_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2473\u001b[0m     size_prods \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m size[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m   2474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_prods \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 2475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected more than 1 value per channel when training, got input size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 30])"]}],"source":["l = []\n","id_ = []\n","for i,batch in enumerate(test_loader):\n","        X =batch.to(device).to(torch.float32)\n","        output = model(X)\n","        softmax_output = F.softmax(output, dim=-1)\n","\n","        l.append(torch.argmax(softmax_output).item())\n","        id_.append(int(X[:,0].item()))\n","\n","ans = pd.DataFrame({'PassengerId':id_,'Survived':l})\n","ans.to_csv('/home/arjun/Desktop/GitHub/Kaggle-competitions/_Datasets/Titanic/submission.csv', index=False)\n","print(\"Saved new O/P\")\n","ans"]},{"cell_type":"markdown","metadata":{},"source":["# Best Score: 0.79"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":26502,"sourceId":3136,"sourceType":"competition"}],"dockerImageVersionId":30626,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
