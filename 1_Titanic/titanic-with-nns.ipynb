{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-01-06T11:29:55.352119Z","iopub.status.busy":"2024-01-06T11:29:55.351831Z","iopub.status.idle":"2024-01-06T11:30:00.167579Z","shell.execute_reply":"2024-01-06T11:30:00.166826Z","shell.execute_reply.started":"2024-01-06T11:29:55.352092Z"},"trusted":true},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader"]},{"cell_type":"markdown","metadata":{},"source":["# TODO\n","- See if ticket and cabin have any importance\n","- Try data imputation instead of fillna"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-06T11:30:00.175161Z","iopub.status.busy":"2024-01-06T11:30:00.174898Z","iopub.status.idle":"2024-01-06T11:30:00.203782Z","shell.execute_reply":"2024-01-06T11:30:00.202893Z","shell.execute_reply.started":"2024-01-06T11:30:00.175129Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv('/home/arjun/Desktop/GitHub/Kaggle-competitions/_Datasets/Titanic/train.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y = df['Survived']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-06T11:30:00.206566Z","iopub.status.busy":"2024-01-06T11:30:00.206322Z","iopub.status.idle":"2024-01-06T11:30:00.220938Z","shell.execute_reply":"2024-01-06T11:30:00.220092Z","shell.execute_reply.started":"2024-01-06T11:30:00.206543Z"},"trusted":true},"outputs":[],"source":["df = df.drop(['Name', 'Ticket', 'Cabin'], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-06T11:30:00.222512Z","iopub.status.busy":"2024-01-06T11:30:00.222193Z","iopub.status.idle":"2024-01-06T11:30:00.343789Z","shell.execute_reply":"2024-01-06T11:30:00.342830Z","shell.execute_reply.started":"2024-01-06T11:30:00.222482Z"},"trusted":true},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-06T11:30:00.345227Z","iopub.status.busy":"2024-01-06T11:30:00.344960Z","iopub.status.idle":"2024-01-06T11:30:00.353449Z","shell.execute_reply":"2024-01-06T11:30:00.352480Z","shell.execute_reply.started":"2024-01-06T11:30:00.345203Z"},"trusted":true},"outputs":[],"source":["df['Sex'] = df['Sex'].replace({'male': 0, 'female': 1})\n","df['Embarked'] = df['Embarked'].replace({'S':1, 'C':2, 'Q':3})"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-06T11:30:00.355104Z","iopub.status.busy":"2024-01-06T11:30:00.354871Z","iopub.status.idle":"2024-01-06T11:30:00.376211Z","shell.execute_reply":"2024-01-06T11:30:00.375457Z","shell.execute_reply.started":"2024-01-06T11:30:00.355081Z"},"trusted":true},"outputs":[],"source":["df.fillna(df.mean(), inplace=True)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_randomized = df.sample(frac=1).reset_index(drop=True)\n","train_df = df_randomized[:800]\n","test_df = df_randomized[800:]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_df"]},{"cell_type":"markdown","metadata":{},"source":["# Model Creation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-06T11:30:00.410359Z","iopub.status.busy":"2024-01-06T11:30:00.410106Z","iopub.status.idle":"2024-01-06T11:30:00.438739Z","shell.execute_reply":"2024-01-06T11:30:00.437939Z","shell.execute_reply.started":"2024-01-06T11:30:00.410336Z"},"trusted":true},"outputs":[],"source":["num_epochs = 5000\n","lr =.001\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-06T11:30:00.443127Z","iopub.status.busy":"2024-01-06T11:30:00.442389Z","iopub.status.idle":"2024-01-06T11:30:00.606235Z","shell.execute_reply":"2024-01-06T11:30:00.605476Z","shell.execute_reply.started":"2024-01-06T11:30:00.443092Z"},"trusted":true},"outputs":[],"source":["class NeuralNet(nn.Module):\n","    def __init__(self, inp_size, h1, h2, h3,  out_size):\n","        super(NeuralNet, self).__init__()\n","        self.inp_size = inp_size\n","        self.lay1 = nn.Linear(inp_size, h1)\n","        self.lay2 = nn.ReLU()\n","        self.lay3 = nn.Linear(h1, h2)\n","        self.lay4 = nn.ReLU()\n","        self.lay5 = nn.Linear(h2, h3)\n","        self.lay6 = nn.ReLU()\n","        self.lay7 = nn.Linear(h3, out_size)\n","        self.drop1 = nn.Dropout(0.5)\n","        self.drop2 = nn.Dropout(0.1)\n","        \n","    def forward(self,x):\n","        out = self.lay1(x)\n","        out = self.lay2(out)\n","        out = self.lay3(out)\n","        out = self.drop1(out)\n","        out = self.lay4(out)\n","        out = self.lay5(out)\n","        # out = self.drop2(out)\n","        out = self.lay6(out)\n","        out = self.lay7(out) # We don't apply sotmax the cross entropy loss will do that for us\n","        return out\n","    \n","model = NeuralNet(8,30,20,30,8).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# class NeuralNet(nn.Module):\n","#     def __init__(self, inp_size, h1, h2, out_size):\n","#         super(NeuralNet, self).__init__()\n","#         self.fc1 = nn.Linear(inp_size, h1)\n","#         self.bn1 = nn.BatchNorm1d(h1)\n","#         self.drop1 = nn.Dropout(0.5)\n","#         self.fc2 = nn.Linear(h1, h2)\n","#         self.bn2 = nn.BatchNorm1d(h2)\n","#         self.drop2 = nn.Dropout(0.5)\n","#         self.fc3 = nn.Linear(h2, out_size)\n","        \n","#     def forward(self, x):\n","#         x = self.fc1(x)\n","#         x = self.bn1(x)\n","#         x = nn.ReLU()(x)\n","#         x = self.drop1(x)\n","#         x = self.fc2(x)\n","#         x = self.bn2(x)\n","#         x = nn.ReLU()(x)\n","#         x = self.drop2(x)\n","#         x = self.fc3(x)\n","#         return x\n","\n","# model = NeuralNet(8, 30, 15, 2).to(device)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-06T11:30:00.607610Z","iopub.status.busy":"2024-01-06T11:30:00.607327Z","iopub.status.idle":"2024-01-06T11:30:00.612091Z","shell.execute_reply":"2024-01-06T11:30:00.611228Z","shell.execute_reply.started":"2024-01-06T11:30:00.607584Z"},"trusted":true},"outputs":[],"source":["lossCategory = nn.CrossEntropyLoss()\n","optimiser = torch.optim.Adam(model.parameters(), lr = lr)"]},{"cell_type":"markdown","metadata":{},"source":["# Training Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-06T11:30:00.613569Z","iopub.status.busy":"2024-01-06T11:30:00.613260Z","iopub.status.idle":"2024-01-06T11:30:00.622669Z","shell.execute_reply":"2024-01-06T11:30:00.621949Z","shell.execute_reply.started":"2024-01-06T11:30:00.613536Z"},"trusted":true},"outputs":[],"source":["train_loader = DataLoader(dataset=torch.tensor(np.array(train_df)), shuffle=True, batch_size=1000)\n","test_loader = DataLoader(dataset=torch.tensor(np.array(test_df)), shuffle=True, batch_size=100)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-06T11:30:00.624057Z","iopub.status.busy":"2024-01-06T11:30:00.623747Z","iopub.status.idle":"2024-01-06T11:32:44.093167Z","shell.execute_reply":"2024-01-06T11:32:44.092168Z","shell.execute_reply.started":"2024-01-06T11:30:00.624034Z"},"trusted":true},"outputs":[],"source":["for epoch in range(num_epochs):\n","    avg_loss = 0\n","    for i,batch in enumerate(train_loader):\n","\n","        y = batch[:,1].to(device).long()\n","        X =torch.cat((batch[:, :1], batch[:, 2:]), dim=1).to(device).to(torch.float32)\n","\n","        # Forward pass\n","        output = model(X)\n","        \n","        # Backward pass\n","        loss = lossCategory(output, y)\n","        loss.backward()\n","        optimiser.step()\n","        optimiser.zero_grad()\n","        avg_loss += loss\n","\n","    if not ((epoch+1)%100): print(f\"Epoch:{epoch+1}/{num_epochs} Loss:{avg_loss/len(train_loader)}\")"]},{"cell_type":"markdown","metadata":{},"source":["# Checking Accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["correct = 0\n","total = 0\n","for i, batch in enumerate(train_loader):\n","    X = torch.cat((batch[:, :1], batch[:, 2:]), dim=1).to(device).to(torch.float32)\n","    y = batch[:, 1].to(device).long()\n","    output = model(X)\n","    softmax_output = F.softmax(output, dim=-1)\n","    _, y_pred = torch.max(softmax_output, dim=-1)\n","    correct += (y_pred == y).sum().item()\n","    total += y.size(0)\n","print('Accuracy:', correct / total * 100)\n","X.shape, y.shape, "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["correct = 0\n","total = 0\n","for i, batch in enumerate(test_loader):\n","    X = torch.cat((batch[:, :1], batch[:, 2:]), dim=1).to(device).to(torch.float32)\n","    y = batch[:, 1].to(device).long()\n","    output = model(X)\n","    softmax_output = F.softmax(output, dim=-1)\n","    _, y_pred = torch.max(softmax_output, dim=-1)\n","    correct += (y_pred == y).sum().item()\n","    total += y.size(0)\n","print('Accuracy:', correct / total * 100)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Inference on Test Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-06T11:32:44.675693Z","iopub.status.busy":"2024-01-06T11:32:44.675413Z","iopub.status.idle":"2024-01-06T11:32:44.695983Z","shell.execute_reply":"2024-01-06T11:32:44.695122Z","shell.execute_reply.started":"2024-01-06T11:32:44.675663Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv('/home/arjun/Desktop/GitHub/Kaggle-competitions/_Datasets/Titanic/test.csv')\n","df = df.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n","df['Sex'] = df['Sex'].replace({'male': 0, 'female': 1})\n","df['Embarked'] = df['Embarked'].replace({'S':1, 'C':2, 'Q':3})\n","df.fillna(df.mean(), inplace=True)\n","ds = torch.tensor(np.array(df))\n","test_loader = torch.utils.data.DataLoader(dataset=ds, shuffle=False, batch_size=1)\n","ds.shape,df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-01-06T11:32:44.704585Z","iopub.status.busy":"2024-01-06T11:32:44.704309Z","iopub.status.idle":"2024-01-06T11:32:44.957845Z","shell.execute_reply":"2024-01-06T11:32:44.956958Z","shell.execute_reply.started":"2024-01-06T11:32:44.704562Z"},"trusted":true},"outputs":[],"source":["l = []\n","id_ = []\n","for i,batch in enumerate(test_loader):\n","        X =batch.to(device).to(torch.float32)\n","        output = model(X)\n","        softmax_output = F.softmax(output, dim=-1)\n","\n","        l.append(torch.argmax(softmax_output).item())\n","        id_.append(int(X[:,0].item()))\n","\n","ans = pd.DataFrame({'PassengerId':id_,'Survived':l})\n","ans.to_csv('/home/arjun/Desktop/GitHub/Kaggle-competitions/_Datasets/Titanic/submission.csv', index=False)\n","print(\"Saved new O/P\")\n","ans"]},{"cell_type":"markdown","metadata":{},"source":["# Best Score: 0.79"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":26502,"sourceId":3136,"sourceType":"competition"}],"dockerImageVersionId":30626,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
