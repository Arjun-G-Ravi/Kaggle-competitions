{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/state-farm-distracted-driver-detection/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1200, 3, 640, 480]), torch.Size([1200]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i in range(10):\n",
    "    dir_path =f'data/imgs/train/c{i}'\n",
    "    files = os.listdir(dir_path)\n",
    "    for img_name in files[:120]:\n",
    "        full_path = dir_path + '/' + img_name\n",
    "        # print(full_path)\n",
    "        img = np.array(Image.open(full_path))\n",
    "        # print(img.shape)\n",
    "        X.append(img)\n",
    "        y.append(i)\n",
    "\n",
    "X = torch.tensor(np.array(X)).float().view(-1, 3, 640, 480)\n",
    "y = torch.tensor(np.array(y)).float()\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DriverDataset(Dataset):\n",
    "    def __init__(self, x_, y_):\n",
    "        self.x_ = x_.to(device)\n",
    "        self.y_ = y_.to(device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x_.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_[index], self.y_[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DriverDataset(X_train, y_train)\n",
    "test_dataset = DriverDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.l1 = nn.Linear(16*158*118,640)\n",
    "        self.l2 = nn.Linear(640, 160)\n",
    "        self.l3 = nn.Linear(160, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x -> (n, 3, 640, 480)\n",
    "        out = self.pool(F.relu(self.conv1(x))) # -> (n, 6, 318, 238)\n",
    "        out = self.pool(F.relu(self.conv2(out))) # -> (n, 16, 158, 118)\n",
    "        out = out.view(-1, 16*158*118)\n",
    "        out = F.relu(self.l1(out))\n",
    "        out = F.relu(self.l2(out))\n",
    "        out = self.l3(out)\n",
    "        return out\n",
    "\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_category = nn.CrossEntropyLoss().to(device)\n",
    "optimiser = torch.optim.AdamW(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c674eb62aa4c9f927708c6f487376f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 2.497697\n",
      "Epoch 10: 0.836714\n",
      "Epoch 15: 0.041116\n",
      "Epoch 20: 0.010473\n"
     ]
    }
   ],
   "source": [
    "for epoch in trange(20):\n",
    "    for i, (x_, y_) in enumerate(train_loader):\n",
    "        x_ = x_.to(torch.float32).to(device)\n",
    "        y_ = F.one_hot(y_.clone().detach().long(), 10).float().to(device)\n",
    "        y_pred = model(x_)\n",
    "        loss = loss_category(y_pred, y_)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "    if (epoch+1)%5 == 0: print(f'Epoch {epoch+1}: {loss.item():3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 99.88888888888889 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "score = 0\n",
    "tot = 0\n",
    "with torch.no_grad():\n",
    "    for i, (x_, y_) in enumerate(train_loader):\n",
    "        x_ = x_.to(torch.float32).to(device)\n",
    "        y_pred = model(x_)\n",
    "        for y1, y_pred1 in zip(y_.int(), torch.argmax(y_pred, dim=1)):\n",
    "            if y1.item() == y_pred1.item(): score += 1\n",
    "            tot += 1\n",
    "print('Train acc:', score*100/ tot, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 74.0 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "score = 0\n",
    "tot = 0\n",
    "with torch.no_grad():\n",
    "    for i, (x_, y_) in enumerate(test_loader):\n",
    "        x_ = x_.to(torch.float32).to(device)\n",
    "        y_pred = model(x_)\n",
    "        for y1, y_pred1 in zip(y_.int(), torch.argmax(y_pred, dim=1)):\n",
    "            if y1.item() == y_pred1.item(): score += 1\n",
    "            tot += 1\n",
    "print('Test acc:', score*100/ tot, '%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best acc: 75.6 % "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
